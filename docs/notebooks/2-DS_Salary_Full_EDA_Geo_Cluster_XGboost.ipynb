{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"padding: 35px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>Getting Started </span></b> </div>\n\n<br>\n\n\nThe goal of this analysis is to **<span style='color:#85BB65'>examine a myriad of factors and their complex interconnections with the aim of predicting</span>** salary outcomes with precision. This study strives to furnish invaluable insights into the current salary trajectories in the realm of data science, simultaneously laying a robust foundation for future explorations into the impact of key determinants like **`experience level`**, **`employment type`**, **`company size`**, and **`geographical location`** on the wage structures within this swiftly advancing profession.\n\n\n\n<br>\n\n![](https://images.pexels.com/photos/164527/pexels-photo-164527.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\n\n<br>\n\n### <b><span style='color:#85BB65'>|</span> Domain Knowledge</b>\n\n<br>\n\n1. **`work_year` [categorical] :** This represents the specific year in which the salary was disbursed. Different years may have different economic conditions which can impact the salary level.\n\n2. **`experience_level` [categorical] :** The level of experience a person holds in a particular job. This is a key determinant in salary calculation as typically, more experienced individuals receive higher pay due to their advanced skills and knowledge.\n\n3. **`employment_type` [categorical] :** The nature of the employment contract such as full-time, part-time, or contractual can greatly influence the salary. Full-time employees often have higher annual salaries compared to their part-time or contractual counterparts.\n\n4. **`job_title` [categorical] :** The role an individual holds within a company. Different roles have different salary scales based on the responsibilities and skills required. For example, managerial roles typically pay more than entry-level positions.\n\n5. **`salary` [numerical] :** The total gross salary paid to the individual. This is directly influenced by factors such as experience level, job title, and employment type.\n\n6. **`salary_currency` [categorical] :** The specific currency in which the salary is paid, denoted by an ISO 4217 code. Exchange rates could affect the value of the salary when converted into different currencies.\n\n7. **`salaryinusd` [numerical] :** The total gross salary amount converted to US dollars. This allows for a uniform comparison of salaries across different countries and currencies.\n\n8. **`employee_residence` [categorical]:** The primary country of residence of the employee, denoted by an ISO 3166 code. The cost of living and prevailing wage rates in the employee's country of residence can impact salary levels.\n\n9. **`remote_ratio` [ratio]:** The proportion of work done remotely. With the rise of remote work, companies may adjust salaries based on the cost of living in the employee's location and the proportion of remote work.\n\n10. **`company_location` [categorical]:**  The location of the employer's main office or the branch that holds the contract. Companies in different locations may offer different salary scales due to varying economic conditions and cost of living.\n\n11. **`company_size` [categorical]:** The median number of employees in the company during the work year. Larger companies often have structured salary scales and may offer higher salaries due to economies of scale and larger revenue streams.\n\n<br>\n\n‚úîÔ∏è **These variables, in combination with appropriate statistical and machine learning techniques, can help predict an individual's salary.**\n\n# <span style=\"color:#E888BB; font-size: 1%;\">0 | INTRODUCTION</span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:170%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>0 | INTRODUCTION </span></b> </div>\n\n<br>\n\n### <b>I <span style='color:#85BB65'>|</span> Preface</b> \n\n<br>\n\nIn this analysis, we have chosen to employ a variety of models, namely **<mark style=\"background-color:#85BB65;color:white;border-radius:4px;opacity:1.0\">Logistic Regression</mark>** , **<mark style=\"background-color:#85BB65;color:white;border-radius:4px;opacity:1.0\">RandomForest</mark>** , and **<mark style=\"background-color:#85BB65;color:white;border-radius:4px;opacity:1.0\">Gradient Boosting Classifier</mark>**. These algorithms are known for their distinct strengths when dealing with diverse data types and structures.\n\nThe reasons for selecting these models are as follows:\n\n1. **Versatility in Handling Diverse Data:** All three models ‚Äì **<span style='color:#85BB65'>Logistic Regression</span>**, **<span style='color:#85BB65'>Random Forest</span>**, and **<span style='color:#85BB65'>Gradient Boosting Classifier</span>** ‚Äì are capable of efficiently managing both numerical and categorical variables in our dataset. This strength is particularly useful given the diverse nature of our dataset, which includes features such as `work year`, `experience level`, `employment type`, `job title`, `salary`, `salary currency`, `salary in USD`, `employee residence`, `remote ratio`, `company location`, and `company size`.\n\n2. **Robustness to Overfitting:** Both **<span style='color:#85BB65'>Random Forest</span>** and **<span style='color:#85BB65'>Gradient Boosting Classifier</span>** excel in managing overfitting. They achieve this by constructing multiple **<mark style=\"background-color:#9BA4B5;color:black;border-radius:4px;opacity:1.0\">decision trees</mark>** and producing the final prediction based on the majority vote or a weighted combination of these trees.\n\n3. **Handling Non-linearity:** Our dataset potentially includes complex and non-linear relationships. Non-linear models like **<span style='color:#85BB65'>Random Forest</span>** and **<span style='color:#85BB65'>Gradient Boosting Classifier</span>** can effectively capture these intricate patterns.\n\n4. **Feature Importance:** **<span style='color:#85BB65'>Random Forest</span>** and **<span style='color:#85BB65'>Gradient Boosting Classifier</span>** provide a straightforward way to estimate feature importance, aligning well with our goal to understand various factors impacting salary.\n\n5. **Effective with Large Data:** Logistic Regression and RandomForest models are known for their ability to efficiently handle large datasets, which is beneficial given the size of our dataset.\n\n<br>\n\n<div style=\"border-radius:10px;border:#85BB65 solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n    üìù Despite experimenting with these three models, it's important to highlight that <strong><mark style=\"background-color:#85BB65;color:white;border-radius:4px;opacity:1.0\">Gradient Boosting Classifier</mark></strong> has demonstrated superior performance among the tested models, with an <strong>accuracy score of 0.32</strong>. However, model selection should always be taken with a grain of salt, and it's generally a good practice to try out a range of models and compare their performance. For this analysis, the ensemble of <strong><span style='color:#85BB65'>Logistic Regression, RandomForest, and Gradient Boosting Classifier</span></strong> provides a comprehensive and robust approach to predicting salary trends.\n</div>\n\n<br>\n\n### <b>II <span style='color:#85BB65'>|</span> Import libraries</b> ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Import Neccessary libraries\nimport numpy as np \nimport pandas as pd\n\n# Import Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Import Statistics libraries\nfrom scipy import stats\nfrom scipy.stats import norm\n\n# Import Scikit-learn for Machine Learning libraries\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\n\n# Import country code libraries\n!pip install pycountry -q\nimport pycountry\n\n#Install plot library\nimport plotly.io as pio\npio.renderers.default='notebook'","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:12:47.696214Z","iopub.execute_input":"2023-05-29T05:12:47.696676Z","iopub.status.idle":"2023-05-29T05:13:23.7107Z","shell.execute_reply.started":"2023-05-29T05:12:47.69664Z","shell.execute_reply":"2023-05-29T05:13:23.709482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>III <span style='color:#85BB65'>|</span> Input data</b> ","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/data-science-salaries-2023/ds_salaries.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.712618Z","iopub.execute_input":"2023-05-29T05:13:23.712953Z","iopub.status.idle":"2023-05-29T05:13:23.758075Z","shell.execute_reply.started":"2023-05-29T05:13:23.712925Z","shell.execute_reply":"2023-05-29T05:13:23.757132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#E888BB; font-size: 1%;\">1 | EXPLORATORY DATA ANALYSIS</span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:170%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>1 | EXPLORATORY DATA ANALYSIS </span></b> </div>\n\n<br>\n\n## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 1. Data Quality</span></b> </div>\n\n### <b>I <span style='color:#85BB65'>|</span> Check null and Missing Values</b> ","metadata":{}},{"cell_type":"code","source":"#check missing ratio\ndata_na = (data.isnull().sum() / len(data)) * 100\ndata_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :data_na})\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.762016Z","iopub.execute_input":"2023-05-29T05:13:23.762742Z","iopub.status.idle":"2023-05-29T05:13:23.808042Z","shell.execute_reply.started":"2023-05-29T05:13:23.762698Z","shell.execute_reply":"2023-05-29T05:13:23.806799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>II <span style='color:#85BB65'>|</span> Check Duplicates</b> ","metadata":{}},{"cell_type":"code","source":"# Handle duplicates\nduplicate_rows_data = data[data.duplicated()]\nprint(\"number of duplicate rows: \", duplicate_rows_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.811275Z","iopub.execute_input":"2023-05-29T05:13:23.811805Z","iopub.status.idle":"2023-05-29T05:13:23.829612Z","shell.execute_reply.started":"2023-05-29T05:13:23.811756Z","shell.execute_reply":"2023-05-29T05:13:23.828392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>III <span style='color:#85BB65'>|</span> Check Unique Value in each columns</b> ","metadata":{}},{"cell_type":"code","source":"# Loop through each column and count the number of distinct values\nfor column in data.columns:\n    num_distinct_values = len(data[column].unique())\n    print(f\"{column}: {num_distinct_values} distinct values\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.831205Z","iopub.execute_input":"2023-05-29T05:13:23.831577Z","iopub.status.idle":"2023-05-29T05:13:23.842737Z","shell.execute_reply.started":"2023-05-29T05:13:23.831548Z","shell.execute_reply":"2023-05-29T05:13:23.841467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>IV <span style='color:#85BB65'>|</span> Explore the data</b> ","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.844112Z","iopub.execute_input":"2023-05-29T05:13:23.845029Z","iopub.status.idle":"2023-05-29T05:13:23.864497Z","shell.execute_reply.started":"2023-05-29T05:13:23.844995Z","shell.execute_reply":"2023-05-29T05:13:23.86317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>V <span style='color:#85BB65'>|</span> Rename the value for better understanding</b> ","metadata":{}},{"cell_type":"code","source":"data['experience_level'] = data['experience_level'].replace({\n    'SE': 'Senior',\n    'EN': 'Entry level',\n    'EX': 'Executive level',\n    'MI': 'Mid/Intermediate level',\n})\n\ndata['employment_type'] = data['employment_type'].replace({\n    'FL': 'Freelancer',\n    'CT': 'Contractor',\n    'FT' : 'Full-time',\n    'PT' : 'Part-time'\n})\ndata['company_size'] = data['company_size'].replace({\n    'S': 'SMALL',\n    'M': 'MEDIUM',\n    'L' : 'LARGE',\n})\ndata['remote_ratio'] = data['remote_ratio'].astype(str)\ndata['remote_ratio'] = data['remote_ratio'].replace({\n    '0': 'On-Site',\n    '50': 'Half-Remote',\n    '100' : 'Full-Remote',\n})","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.86584Z","iopub.execute_input":"2023-05-29T05:13:23.866229Z","iopub.status.idle":"2023-05-29T05:13:23.890766Z","shell.execute_reply.started":"2023-05-29T05:13:23.866198Z","shell.execute_reply":"2023-05-29T05:13:23.889456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>VI <span style='color:#85BB65'>|</span> Group the job title</b> ","metadata":{}},{"cell_type":"code","source":"def assign_broader_category(job_title):\n    data_engineering = [\"Data Engineer\", \"Data Analyst\", \"Analytics Engineer\", \"BI Data Analyst\", \"Business Data Analyst\", \"BI Developer\", \"BI Analyst\", \"Business Intelligence Engineer\", \"BI Data Engineer\", \"Power BI Developer\"]\n    data_scientist = [\"Data Scientist\", \"Applied Scientist\", \"Research Scientist\", \"3D Computer Vision Researcher\", \"Deep Learning Researcher\", \"AI/Computer Vision Engineer\"]\n    machine_learning = [\"Machine Learning Engineer\", \"ML Engineer\", \"Lead Machine Learning Engineer\", \"Principal Machine Learning Engineer\"]\n    data_architecture = [\"Data Architect\", \"Big Data Architect\", \"Cloud Data Architect\", \"Principal Data Architect\"]\n    management = [\"Data Science Manager\", \"Director of Data Science\", \"Head of Data Science\", \"Data Scientist Lead\", \"Head of Machine Learning\", \"Manager Data Management\", \"Data Analytics Manager\"]\n    \n    if job_title in data_engineering:\n        return \"Data Engineering\"\n    elif job_title in data_scientist:\n        return \"Data Science\"\n    elif job_title in machine_learning:\n        return \"Machine Learning\"\n    elif job_title in data_architecture:\n        return \"Data Architecture\"\n    elif job_title in management:\n        return \"Management\"\n    else:\n        return \"Other\"\n\n# Apply the function to the 'job_title' column and create a new column 'job_category'\ndata['job_category'] = data['job_title'].apply(assign_broader_category)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.89224Z","iopub.execute_input":"2023-05-29T05:13:23.892612Z","iopub.status.idle":"2023-05-29T05:13:23.907646Z","shell.execute_reply.started":"2023-05-29T05:13:23.892582Z","shell.execute_reply":"2023-05-29T05:13:23.906597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 2. Dealing with Inflation rate</span></b> </div>\n\n\n### <b>VII <span style='color:#85BB65'>|</span> Adjusted the income to Present Value</b> \n<br>\n\n\n![](https://www.halifax.co.uk/assets/financial-planning-centre/inflation-projection.png)\n\n\n<br>\n\nIn order to accurately compare salaries across different years, it is essential to account for inflation. Inflation is the rate at which the general price levels of goods and services increase over time. By adjusting salaries to a common currency and year, we can make meaningful comparisons between them.\n\n<br>\n\n![](https://timeseriesreasoning.files.wordpress.com/2021/05/88f72-1gjxkmcxhudin7t07swj0mq.png)\n\n\n\n<br>\n\nTo adjust salaries from different years to their present value for comparison purposes. We will be using a dataset containing information on employee salaries, work years, and currency.\n\n<br>\n\n### <b><span style='color:#85BB65'>|</span> Explanation:</b>\n\n<br>\n\n1. **Define inflation rates** for the United States (US) and global markets. These rates will be used to adjust the salaries based on the year and currency.\n\n2. Create a function **adjust_salary()** that takes a row from the dataset as input and calculates the adjusted salary based on the work year, original salary, and currency. If the work year is 2023, the salary does not need to be adjusted, and the original salary is returned.\n\n3. Determine the **number of years between the work year and 2023** . Use the appropriate inflation rate based on the currency, either the US or global inflation rate.\n\n4. Calculate the adjusted salary by **applying the inflation rate** to the original salary for each year from the work year to 2023.\n\n5. **Apply the adjust_salary() function** to the dataset using the apply() method, and create a new column 'adjusted_salary' with the adjusted salary values.\n<br>\n\n> By accounting for inflation, we can gain a better understanding of the true value of salaries in different years and currencies.","metadata":{}},{"cell_type":"code","source":"# Inflation rates\nus_inflation_rates = {2019: 0.0181, 2020: 0.0123, 2021: 0.0470, 2022: 0.065}\nglobal_inflation_rates = {2019: 0.0219, 2020: 0.0192, 2021: 0.0350, 2022: 0.088}\n\n# Function to adjust salary\ndef adjust_salary(row):\n    year = row['work_year']\n    original_salary = row['salary_in_usd']\n    currency = row['salary_currency']\n\n    if year == 2023:\n        return original_salary\n\n    adjusted_salary = original_salary\n    for y in range(year, 2023):\n        if currency == 'USD':\n            inflation_rate = us_inflation_rates[y]\n        else:\n            inflation_rate = global_inflation_rates[y]\n\n        adjusted_salary *= (1 + inflation_rate)\n\n    return adjusted_salary\n\n# Apply the function to the dataset\ndata['adjusted_salary'] = data.apply(adjust_salary, axis=1)\n\n#------------\n#credit : @rrrrrrita\n#------------","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:23.908989Z","iopub.execute_input":"2023-05-29T05:13:23.909394Z","iopub.status.idle":"2023-05-29T05:13:24.011276Z","shell.execute_reply.started":"2023-05-29T05:13:23.909361Z","shell.execute_reply":"2023-05-29T05:13:24.010317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 3. Univariative Analysis</span></b> </div>\n\n### <b>VIII <span style='color:#85BB65'>|</span> Job Distribution</b> ","metadata":{}},{"cell_type":"code","source":"value_counts = data['job_category'].value_counts(normalize=True) * 100\n\nfig, ax = plt.subplots(figsize=(12, 6))\ntop_n = min(17, len(value_counts))\nax.barh(value_counts.index[:top_n], value_counts.values[:top_n])\nax.set_xlabel('Percentage')\nax.set_ylabel('Job Category')\nax.set_title('Job Titles Percentage')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:24.014856Z","iopub.execute_input":"2023-05-29T05:13:24.015758Z","iopub.status.idle":"2023-05-29T05:13:24.321114Z","shell.execute_reply.started":"2023-05-29T05:13:24.015722Z","shell.execute_reply":"2023-05-29T05:13:24.319942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>IX <span style='color:#85BB65'>|</span> Distribution across different employment types</b> ","metadata":{}},{"cell_type":"code","source":"# Salary distribution across different employment types\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=data, x='employment_type', y='adjusted_salary')\nplt.title('Salary Distribution Across Different Employment Types')\nplt.xlabel('Employment Type')\nplt.ylabel('Adjusted Salary')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:24.322673Z","iopub.execute_input":"2023-05-29T05:13:24.32338Z","iopub.status.idle":"2023-05-29T05:13:24.621404Z","shell.execute_reply.started":"2023-05-29T05:13:24.323335Z","shell.execute_reply":"2023-05-29T05:13:24.620318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>X <span style='color:#85BB65'>|</span> Distribution of Salary</b> ","metadata":{}},{"cell_type":"code","source":"# Create a list of the columns to analyze\ncolumns = ['adjusted_salary']\n\n# Loop over the columns and plot the distribution of each variable\nfor col in columns:\n    # Plot the distribution of the data\n    sns.histplot(data[col], kde=True)\n\n    # Fit a normal distribution to the data\n    (mu, sigma) = stats.norm.fit(data[col])\n    print('{}: mu = {:.2f}, sigma = {:.2f}'.format(col, mu, sigma))\n\n    # Calculate the skewness and kurtosis of the data\n    print('{}: Skewness: {:.2f}'.format(col, data[col].skew()))\n    print('{}: Kurtosis: {:.2f}'.format(col, data[col].kurt()))\n\n    # Add the fitted normal distribution to the plot\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, y, label='Normal fit')\n\n    # Add labels and title to the plot\n    plt.xlabel(col)\n    plt.ylabel('Frequency')\n    plt.title('Distribution of {}'.format(col))\n\n    # Plot the QQ-plot\n    fig = plt.figure()\n    stats.probplot(data[col], plot=plt)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:24.622806Z","iopub.execute_input":"2023-05-29T05:13:24.62311Z","iopub.status.idle":"2023-05-29T05:13:25.269147Z","shell.execute_reply.started":"2023-05-29T05:13:24.623084Z","shell.execute_reply":"2023-05-29T05:13:25.267904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>XI <span style='color:#85BB65'>|</span> Boxplot and Swarmplot of Adjusted Salary</b> ","metadata":{}},{"cell_type":"code","source":"# apply formatting to describe method for 'adjusted_salary' column\nformatted_data = data.loc[:, 'adjusted_salary'].describe().apply(lambda x: f'{x:.2f}')\n\n# create boxplot and swarmplot for 'adjusted_salary' column\nplt.figure(figsize=(8, 6))\nsns.boxplot(x=data['adjusted_salary'], palette='coolwarm')\nsns.swarmplot(x=data['adjusted_salary'], color='blue', alpha=0.4, size=2.5)\nplt.ylabel('Adjusted Salary')\nplt.title('Boxplot and Swarmplot of Adjusted Salary')\nplt.show()\n\n# apply styling to formatted data\nstyled_data = formatted_data.to_frame().style \\\n    .background_gradient(cmap='Blues') \\\n    .set_properties(**{'text-align': 'center', 'border': '1px solid black'})\n\n# display styled data\ndisplay(styled_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:25.270992Z","iopub.execute_input":"2023-05-29T05:13:25.273127Z","iopub.status.idle":"2023-05-29T05:13:54.11897Z","shell.execute_reply.started":"2023-05-29T05:13:25.273089Z","shell.execute_reply":"2023-05-29T05:13:54.117911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 3. Bivariative Analysis</span></b> </div>\n\n### <b>XII <span style='color:#85BB65'>|</span> Median salary by job title</b> ","metadata":{}},{"cell_type":"code","source":"df = data.copy()\n\n#  Median salary by job title\npivot_table = df.pivot_table(values='adjusted_salary', index='job_category', columns='work_year', aggfunc='median')\nplt.figure(figsize=(14, 6))\nsns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\nplt.title('Median Salary by Year')\nplt.xlabel('Year')\nplt.ylabel('Job Title')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:54.120613Z","iopub.execute_input":"2023-05-29T05:13:54.121161Z","iopub.status.idle":"2023-05-29T05:13:54.597956Z","shell.execute_reply.started":"2023-05-29T05:13:54.121121Z","shell.execute_reply":"2023-05-29T05:13:54.59715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 4. Multivariative Analysis</span></b> </div>\n\n### <b>XIII <span style='color:#85BB65'>|</span> Salary comparison between employee residence and company location</b> ","metadata":{}},{"cell_type":"code","source":"# Salary comparison between employee residence and company location\nplt.figure(figsize=(15, 10))\nsns.scatterplot(data=df, x='employee_residence', y='company_location', hue='adjusted_salary', size='adjusted_salary', sizes=(20, 200), alpha=0.5)\nplt.title('Salary Comparison between Employee Residence and Company Location')\nplt.xlabel('Employee Residence')\nplt.ylabel('Company Location')\nplt.xticks(rotation=90)\nplt.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:54.599405Z","iopub.execute_input":"2023-05-29T05:13:54.599984Z","iopub.status.idle":"2023-05-29T05:13:56.112072Z","shell.execute_reply.started":"2023-05-29T05:13:54.599954Z","shell.execute_reply":"2023-05-29T05:13:56.11077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#E888BB; font-size: 1%;\">2 | GEOSPATIAL ANALYSIS</span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:150%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>2 | GEOSPATIAL ANALYSIS </span></b> </div>\n\n### <b>I <span style='color:#85BB65'>|</span> Convert the country code to the country name</b> ","metadata":{}},{"cell_type":"code","source":"# Function to convert ISO 3166 country code to country name\ndef country_code_to_name(country_code):\n    try:\n        return pycountry.countries.get(alpha_2=country_code).name\n    except:\n        return country_code\n    # Function to convert country code to full name\ndef country_code_to_name(code):\n    try:\n        country = pycountry.countries.get(alpha_2=code)\n        return country.name\n    except:\n        return None","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:56.113713Z","iopub.execute_input":"2023-05-29T05:13:56.114157Z","iopub.status.idle":"2023-05-29T05:13:56.12167Z","shell.execute_reply.started":"2023-05-29T05:13:56.114118Z","shell.execute_reply":"2023-05-29T05:13:56.120662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>II <span style='color:#85BB65'>|</span> Average salary by location of the organization</b> ","metadata":{}},{"cell_type":"code","source":"# Convert country codes to names\ndf['company_location'] = df['company_location'].apply(country_code_to_name)\ndf['employee_residence'] = df['employee_residence'].apply(country_code_to_name)\n\n# Average salary by company_location\navg_salary_by_location = df.groupby('company_location', as_index=False)['adjusted_salary'].mean()\n\nfig1 = px.choropleth(avg_salary_by_location,\n                     locations='company_location',\n                     locationmode='country names',\n                     color='adjusted_salary',\n                     hover_name='company_location',\n                     color_continuous_scale=px.colors.sequential.Plasma,\n                     title='Average Salary by Company Location',\n                     labels={'adjusted_salary': 'Average Adjusted Salary'},\n                     projection='natural earth')\n\nfig1.show()\n\n# Average salary by company_location\navg_salary_by_location = df.groupby('company_location')['adjusted_salary'].mean().sort_values(ascending=False)\nplt.figure(figsize=(14, 6))\nsns.barplot(x=avg_salary_by_location.index, y=avg_salary_by_location, color='grey')\nplt.title('Average Salary by Company Location (Yearly)')\nplt.xlabel('Company Location')\nplt.ylabel('Average Adjusted Salary (Yearly)')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:56.123269Z","iopub.execute_input":"2023-05-29T05:13:56.123695Z","iopub.status.idle":"2023-05-29T05:13:58.859389Z","shell.execute_reply.started":"2023-05-29T05:13:56.123649Z","shell.execute_reply":"2023-05-29T05:13:58.85828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>III <span style='color:#85BB65'>|</span> Which country generate the highest wages</b> ","metadata":{}},{"cell_type":"code","source":"# Average salary by employee_residence\navg_salary_by_residence = df.groupby('employee_residence', as_index=False)['adjusted_salary'].mean()\n\nfig2 = px.choropleth(avg_salary_by_residence,\n                     locations='employee_residence',\n                     locationmode='country names',\n                     color='adjusted_salary',\n                     hover_name='employee_residence',\n                     color_continuous_scale=px.colors.sequential.Plasma,\n                     title='Average Salary by Employee Residence',\n                     labels={'adjusted_salary': 'Average Adjusted Salary'},\n                     projection='natural earth')\n\nfig2.show()\n\n# Average salary by employee_residence\navg_salary_by_residence = df.groupby('employee_residence')['adjusted_salary'].mean().sort_values(ascending=False)\nplt.figure(figsize=(14, 6))\nsns.barplot(x=avg_salary_by_residence.index, y=avg_salary_by_residence.values, color='grey')\nplt.title('Average Salary by Employee Residence (Yearly)')\nplt.xlabel('Employee Residence')\nplt.ylabel('Average Adjusted Salary (Yearly)')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:58.86062Z","iopub.execute_input":"2023-05-29T05:13:58.860929Z","iopub.status.idle":"2023-05-29T05:13:59.938274Z","shell.execute_reply.started":"2023-05-29T05:13:58.860902Z","shell.execute_reply":"2023-05-29T05:13:59.9372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>IV <span style='color:#85BB65'>|</span> Which country doesn't demand that you work on the job</b> ","metadata":{}},{"cell_type":"code","source":"# Filter for remote_ratio of 100\nremote_100 = data[data['remote_ratio'] == 'Full-Remote']\n\n# Aggregate by country code\ncountry_counts = remote_100['company_location'].value_counts().reset_index()\ncountry_counts.columns = ['country_code', 'count']\n\n# Convert country codes to full names\ncountry_counts['country_name'] = country_counts['country_code'].apply(country_code_to_name)\n\n# Create the choropleth map with a logarithmic color scale\nfig = px.choropleth(country_counts, \n                    locations='country_name', \n                    locationmode='country names',\n                    color=np.log10(country_counts['count']), \n                    hover_name='country_name',\n                    hover_data=['count'],\n                    color_continuous_scale=px.colors.sequential.Plasma,\n                    title='Choropleth Map of Full-Remote Company Locations',\n                    projection='natural earth')\n\n# Customize the colorbar to show the original count values\nfig.update_coloraxes(colorbar=dict(title='Count (Log Scale)', tickvals=[0, 1, 2, 3], ticktext=['1', '10', '100', '1000']))\n\n# Show the map\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:13:59.940078Z","iopub.execute_input":"2023-05-29T05:13:59.940461Z","iopub.status.idle":"2023-05-29T05:14:00.031527Z","shell.execute_reply.started":"2023-05-29T05:13:59.940431Z","shell.execute_reply":"2023-05-29T05:14:00.030496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>V <span style='color:#85BB65'>|</span> Where is the business situated?</b> ","metadata":{}},{"cell_type":"code","source":"# Filter for remote_ratio of 100\nremote_0 = data[data['remote_ratio'] == 'On-Site']\n\n# Aggregate by country code\ncountry_counts = remote_0['company_location'].value_counts().reset_index()\ncountry_counts.columns = ['country_code', 'count']\n\n# Convert country codes to full names\ncountry_counts['country_name'] = country_counts['country_code'].apply(country_code_to_name)\n\n# Create the choropleth map with a logarithmic color scale\nfig = px.choropleth(country_counts, \n                    locations='country_name', \n                    locationmode='country names',\n                    color=np.log10(country_counts['count']), \n                    hover_name='country_name',\n                    hover_data=['count'],\n                    color_continuous_scale=px.colors.sequential.Plasma,\n                    title='Choropleth Map of On-Site Company Locations',\n                    projection='natural earth')\n\n# Customize the colorbar to show the original count values\nfig.update_coloraxes(colorbar=dict(title='Count (company)', tickvals=[0, 1, 2, 3], ticktext=['1', '10', '100', '1000']))\n\n# Show the map\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.033049Z","iopub.execute_input":"2023-05-29T05:14:00.033366Z","iopub.status.idle":"2023-05-29T05:14:00.112808Z","shell.execute_reply.started":"2023-05-29T05:14:00.033338Z","shell.execute_reply":"2023-05-29T05:14:00.111778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#85BB65'>|</span> Summary of Findings</b>\n\n<br>\n\n* The distribution of adjusted salaries reveals that **most data science professionals earn between 100,000 and 180500 USD per anunum**. However, there are a few high earners that make significantly more than the average.\n\n* The average salary by company location shows that data scientists working for companies based in countries such as **Israel, USA, and Russia tend to have higher average salaries**. On the other hand, companies located in region like **South East Asia, Africa, and Eastern Europe pay comparatively lower average salaries** to data science professionals.\n\n* The analysis of average salary by employee residence indicates that data scientists residing in countries like **Israel, USA, and Malaysia generally earn higher average salaries**. Conversely, data scientists living in countries like Slovakia, Morocco, and North Macedonia have lower average salaries.\n\n* The salary comparison between employee residence and company location reveals that while some data scientists earn high salaries by working for companies based in countries with high-paying job markets, others may need to relocate or work remotely to benefit from these opportunities.\n\n<br>\n\n> In conclusion, this analysis of data science job salaries highlights the impact of various factors, such as company location and employee residence, on salary trends. By understanding these patterns, job seekers and employers can make informed decisions about job opportunities, compensation packages, and talent acquisition strategies.\n\n# <span style=\"color:#E888BB; font-size: 1%;\">3 | CORRELATION </span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:150%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>3 | CORRELATION </span></b> </div>\n\n## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 1.Dealing with categorical and numerical column</span></b> </div>\n    \n### <b>I <span style='color:#85BB65'>|</span> Select Columns</b> ","metadata":{}},{"cell_type":"code","source":"categorical_columns = ['experience_level', 'employment_type', 'remote_ratio','company_size','job_category']\nnumerical_columns = ['adjusted_salary']","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.114086Z","iopub.execute_input":"2023-05-29T05:14:00.114394Z","iopub.status.idle":"2023-05-29T05:14:00.119554Z","shell.execute_reply.started":"2023-05-29T05:14:00.114366Z","shell.execute_reply":"2023-05-29T05:14:00.118557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 2.Dealing with categorical variables</span></b> </div>\n\n### <b>II <span style='color:#85BB65'>|</span> Create Dummy Variables</b> ","metadata":{}},{"cell_type":"code","source":"dummy_variables = pd.get_dummies(df, columns=categorical_columns, drop_first=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.121217Z","iopub.execute_input":"2023-05-29T05:14:00.122221Z","iopub.status.idle":"2023-05-29T05:14:00.140733Z","shell.execute_reply.started":"2023-05-29T05:14:00.12219Z","shell.execute_reply":"2023-05-29T05:14:00.139906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 2.Preprocessing : Standard Scaler</span></b> </div>\n\n### <b>III <span style='color:#85BB65'>|</span> Preprocessing and Scaling the data</b> \n\nPreprocessing is a crucial step before training the model. In this case, numerical features are standardized (mean removed and scaled to unit variance), and categorical features are one-hot encoded. **<span style='color:#85BB65'>Standardization</span>** is not required for all models but is generally a good practice. **<span style='color:#85BB65'>One-hot encoding</span>** is necessary for categorical variables to be correctly understood by the machine learning model.\n\nThe **<mark style=\"background-color:#85BB65;color:white;border-radius:5px;opacity:1.0\">StandardScaler</mark>** in sklearn is based on the assumption that the data, Y, follows a distribution that might not necessarily be Gaussian (normal), but we still transform it in a way that its distribution will have a mean value 0 and standard deviation of 1.</p>\n\n<p>In other words, given a feature vector <em>x</em>, it modifies the values as follows:</p>\n\n<p class=\"formulaDsp\">\n\\[ Y_i = \\frac{x_i - \\mu(\\vec{x})}{\\sigma(\\vec{x})} \\]\n</p>\n\n**where:**\n<ul>\n<li>\\( x_i \\) is the i-th element of the original feature vector \\( \\vec{x} \\),</li>\n<li>\\( \\mu(\\vec{x}) \\) is the mean of the feature vector, and</li>\n<li>\\( \\sigma(\\vec{x}) \\) is the standard deviation of the feature vector.</li>\n</ul>\n\n<p>The transformed data \\( Y \\) (each \\( Y_i \\)) will have properties such that \\( mean(Y) = 0 \\) and \\( std(Y) = 1 \\).</p>\n\n> This transformation is also known as Z-score normalization.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# Scale the numerical columns\nscaled_numerical = scaler.fit_transform(df[numerical_columns])\n\n# Convert the scaled numerical columns\nscaled_numerical_df = pd.DataFrame(scaled_numerical, columns=numerical_columns)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.142371Z","iopub.execute_input":"2023-05-29T05:14:00.142734Z","iopub.status.idle":"2023-05-29T05:14:00.152613Z","shell.execute_reply.started":"2023-05-29T05:14:00.1427Z","shell.execute_reply":"2023-05-29T05:14:00.15176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the original numerical columns\ndummy_variables = dummy_variables.drop(numerical_columns, axis=1)\n\n# Concatenate the dummy variables and scaled numerical columns\nprocessed_df = pd.concat([dummy_variables, scaled_numerical_df], axis=1)\nprocessed_df = processed_df.drop(['work_year', 'salary','salary_in_usd'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.153714Z","iopub.execute_input":"2023-05-29T05:14:00.154074Z","iopub.status.idle":"2023-05-29T05:14:00.16509Z","shell.execute_reply.started":"2023-05-29T05:14:00.154048Z","shell.execute_reply":"2023-05-29T05:14:00.164257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>IV <span style='color:#85BB65'>|</span> Corelation Matrix with dummy variables</b> ","metadata":{}},{"cell_type":"code","source":"correlation_matrix = processed_df.corr()\n\n#Graph I.\nplt.figure(figsize=(15, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\nplt.title(\"Correlation Matrix Heatmap\")\nplt.show()\n\ncorr = processed_df.corr()\ntarget_corr = corr['adjusted_salary'].drop('adjusted_salary')\n\n# Sort correlation values in descending order\ntarget_corr_sorted = target_corr.sort_values(ascending=False)\n\n#Graph II\n# Create a heatmap of the correlations with the target column\nsns.set(font_scale=0.8)\nsns.set_style(\"white\")\nsns.set_palette(\"PuBuGn_d\")\nsns.heatmap(target_corr_sorted.to_frame(), cmap=\"coolwarm\", annot=True, fmt='.2f')\nplt.title('Correlation with Salary')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:00.166138Z","iopub.execute_input":"2023-05-29T05:14:00.16644Z","iopub.status.idle":"2023-05-29T05:14:02.364999Z","shell.execute_reply.started":"2023-05-29T05:14:00.166406Z","shell.execute_reply":"2023-05-29T05:14:02.363923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#E888BB; font-size: 1%;\">4 | PREDICTIVE ANALYSIS</span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:150%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>4 | PREDICTIVE ANALYSIS</span></b> </div>\n\n<br>\n\nIn this study, we aim to build a machine learning model that can predict data science job salaries based on a given set of features, such as `employment type`, `job category`, `experience level`, `employee residence`, `remote work ratio`, `company location`, and `company size`.To achieve our goal, we use a dataset containing information on data science job salaries and related features. \n\n### <b><span style='color:#85BB65'>|</span> Important Features</b>\n\n<br>\n\n1. **`experience_level` [categorical] :** The experience level in the job during the year.\n\n2. **`employment_type` [categorical] :** The type of employment for the role.\n\n3. **`job_category` [categorical] :** The role worked in during the year.\n\n4. **`adjusted_salary` [numerical] :** The present value salary in USD.\n\n5. **`employee_residence` [categorical]:** Employee's primary country of residence in during the work year as an ISO 3166 country code.\n\n6. **`remote_ratio` [ratio]:** The overall amount of work done remotely.\n\n7. **`company_location` [categorical]:** The country of the employer's main office or contracting branch.\n\n8. **`company_size` [categorical]:** The median number of people that worked for the company during the year as an ISO 3166 country code.","metadata":{}},{"cell_type":"markdown","source":"### <b>I <span style='color:#85BB65'>|</span> Data preparation</b> ","metadata":{}},{"cell_type":"code","source":"# create dictionary of country code to country name mappings\ncountry_map = {}\nfor country in pycountry.countries:\n    country_map[country.alpha_2] = country.name\n# replace values in 'employee_residence' column using dictionary\ndata['employee_residence'] = data['employee_residence'].replace(country_map)\ndata['company_location'] = data['company_location'].replace(country_map)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:02.36642Z","iopub.execute_input":"2023-05-29T05:14:02.366774Z","iopub.status.idle":"2023-05-29T05:14:02.534725Z","shell.execute_reply.started":"2023-05-29T05:14:02.366743Z","shell.execute_reply":"2023-05-29T05:14:02.533697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\ndf = df.drop(['work_year','salary','salary_currency','salary_in_usd','salary_in_usd','job_title'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:02.536915Z","iopub.execute_input":"2023-05-29T05:14:02.537303Z","iopub.status.idle":"2023-05-29T05:14:02.545095Z","shell.execute_reply.started":"2023-05-29T05:14:02.537269Z","shell.execute_reply":"2023-05-29T05:14:02.544179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:02.55171Z","iopub.execute_input":"2023-05-29T05:14:02.55205Z","iopub.status.idle":"2023-05-29T05:14:02.5669Z","shell.execute_reply.started":"2023-05-29T05:14:02.55202Z","shell.execute_reply":"2023-05-29T05:14:02.566057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 1. Clustering Analysis </span></b> </div>\n\n### <b>II <span style='color:#85BB65'>|</span> Preprocessing</b> \n\n<br>\n\nThe preprocessing step involved encoding of categorical variables and MinMax scaling for numerical variables:\n\n#### **<span style='color:#85BB65'>Label encoding:</span>** \n Label encoding was applied to the categorical features. The categories of each feature were assigned a unique numerical label.\n\n#### **<span style='color:#85BB65'>MinMax scaling:</span>** \n MinMax scaling was applied to the numerical features. This scaling method transforms the data to fit within a specific range, typically (0, 1). In this case, `adjusted_salary` were scaled.","metadata":{}},{"cell_type":"code","source":"# Create a copy of the dataframe to not alter the original\ndf_preprocessed = df.copy()\n\n# Preprocessing: Label encoding for categorical variables\nle = LabelEncoder()\ncategorical_features = ['experience_level', 'employment_type', 'job_category', 'employee_residence', 'company_location', 'company_size', 'remote_ratio']\nfor feature in categorical_features:\n    df_preprocessed[feature] = le.fit_transform(df[feature])\n\n# Preprocessing: MinMax scaling for numerical/ratio variables\nmm = MinMaxScaler()\nnumerical_features = ['adjusted_salary']\nfor feature in numerical_features:\n    df_preprocessed[feature] = mm.fit_transform(df[feature].values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:02.568404Z","iopub.execute_input":"2023-05-29T05:14:02.569005Z","iopub.status.idle":"2023-05-29T05:14:02.595662Z","shell.execute_reply.started":"2023-05-29T05:14:02.56897Z","shell.execute_reply":"2023-05-29T05:14:02.593761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>III <span style='color:#85BB65'>|</span> T-SNE Clustering</b> \n\n**<span style='color:#85BB65'>t-SNE (t-Distributed Stochastic Neighbor Embedding):</span>** was employed for dimensionality reduction to visualize high-dimensional data in 2D.\n\n<div style=\"border-radius:10px;border:#85BB65 solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\nWe used the following parameters: n_components=2, random_state=42, perplexity=50, and learning_rate=200.\n</div>\n\n<br>\n\nThe results of t-SNE were visualized in a **scatter plot**, where data points were colored by `adjusted_salary`.","metadata":{}},{"cell_type":"code","source":"# Apply t-SNE with different perplexity and learning rate\ntsne = TSNE(n_components=2, random_state=42, perplexity=50, learning_rate=200)\ntsne_results = tsne.fit_transform(df_preprocessed)\n\n# Plotly Interactive plot\ndf_tsne = pd.DataFrame(data = tsne_results, columns = ['Dim_1', 'Dim_2'])\ndf_tsne['adjusted_salary'] = df['adjusted_salary']\nfig = px.scatter(df_tsne, x='Dim_1', y='Dim_2', color='adjusted_salary', title='t-SNE plot colored by Salary')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:02.597332Z","iopub.execute_input":"2023-05-29T05:14:02.597659Z","iopub.status.idle":"2023-05-29T05:14:21.968838Z","shell.execute_reply.started":"2023-05-29T05:14:02.597632Z","shell.execute_reply":"2023-05-29T05:14:21.967895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#85BB65'>|</span> Intepret the Results </b> \n\n**<span style='color:#85BB65'>From the t-SNE plot :</span>** The x-axis and y-axis represent the two dimensions (Dim_1 and Dim_2) of the t-SNE plot. These dimensions don't have a specific meaning, but they are constructed in a way that tries to preserve the structure of the high-dimensional data in the 2D space.\n\nThe points are scattered across the plot, and there doesn't seem to be a clear separation of clusters. This could suggest that the data doesn't have a strong structure, or it could be that the t-SNE parameters need to be adjusted.\n\nThe color bar on the right shows the salary range from 100k to 500k. It seems like there are points of all colors across the plot, which suggests that there isn't a clear relationship between the t-SNE dimensions and the salary.\n\n\n## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> 2. Salary Prediction</span></b> </div>\n### <b>II <span style='color:#85BB65'>|</span> Remove Outliers with IQR method</b> ","metadata":{}},{"cell_type":"code","source":"# Outlier detection using IQR method\nQ1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\ndf = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:21.969974Z","iopub.execute_input":"2023-05-29T05:14:21.970292Z","iopub.status.idle":"2023-05-29T05:14:21.998017Z","shell.execute_reply.started":"2023-05-29T05:14:21.970263Z","shell.execute_reply":"2023-05-29T05:14:21.99689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>III <span style='color:#85BB65'>|</span> Categorize salary to seven ranges</b> ","metadata":{}},{"cell_type":"code","source":"# Calculate quantiles for salary bin edges\nquantiles = [0, 1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 1]\nbin_edges = [df['adjusted_salary'].quantile(q) for q in quantiles]\n\n# Convert the continuous salary variable into 7 discrete bins based on quantiles\nsalary_labels = ['low', 'low-mid', 'mid', 'mid-high', 'high', 'very-high', 'Top']\ndf['salary_range'] = pd.cut(df['adjusted_salary'], bins=bin_edges, labels=salary_labels, include_lowest=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:21.999738Z","iopub.execute_input":"2023-05-29T05:14:22.000443Z","iopub.status.idle":"2023-05-29T05:14:22.018838Z","shell.execute_reply.started":"2023-05-29T05:14:22.000399Z","shell.execute_reply":"2023-05-29T05:14:22.01782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>IV <span style='color:#85BB65'>|</span> Preprocessing</b> ","metadata":{}},{"cell_type":"code","source":"# Label encoding for categorical features\nencoder = LabelEncoder()\ncategorical_features = ['employment_type', 'job_category', 'experience_level', \n                        'employee_residence', 'remote_ratio', 'company_location', 'company_size']\nfor feature in categorical_features:\n    df[feature] = encoder.fit_transform(df[feature])\n# Split the dataset into training and testing sets\nX = df.drop([\"adjusted_salary\", \"salary_range\"], axis=1)\ny = df[\"salary_range\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:22.020341Z","iopub.execute_input":"2023-05-29T05:14:22.021024Z","iopub.status.idle":"2023-05-29T05:14:22.044707Z","shell.execute_reply.started":"2023-05-29T05:14:22.020979Z","shell.execute_reply":"2023-05-29T05:14:22.043927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b>V <span style='color:#85BB65'>|</span> Traning and Validation</b> ","metadata":{}},{"cell_type":"code","source":"# Define the models\nmodels = [\n    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n    ('Random Forest', RandomForestClassifier()),\n    ('Gradient Boosting', GradientBoostingClassifier())\n]\n\n# Model training, evaluation, and selection\nbest_model = None\nbest_score = -np.inf\n\nprint(\"Model performance:\")\nfor name, model in models:\n    pipeline = Pipeline([('scaler', StandardScaler()), ('model', model)])\n    pipeline.fit(X_train, y_train)\n    \n    y_pred = pipeline.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    print(f\"{name} - Accuracy: {accuracy:.2f}\")\n    \n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = pipeline\n\nprint(f\"Best model: {best_model.named_steps['model']} with accuracy: {best_score:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:22.046189Z","iopub.execute_input":"2023-05-29T05:14:22.046836Z","iopub.status.idle":"2023-05-29T05:14:24.516745Z","shell.execute_reply.started":"2023-05-29T05:14:22.046795Z","shell.execute_reply":"2023-05-29T05:14:24.51565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> VI | Confusion Matrix</span></b> </div>\n\nThe trained model is evaluated on the **test set**. **<mark style=\"background-color:#85BB65;color:white;border-radius:5px;opacity:1.0\">Confusion matrix</mark>** is used to visualize the performance of the model. It shows the true positive, true negative, false positive, and false negative predictions of the model.\n\n<br>\n\n![](https://miro.medium.com/v2/resize:fit:1218/1*jMs1RmSwnYgR9CsBw-z1dw.png)\n\n#### **<span style='color:#85BB65'>Precision:</span>**\n\nPrecision is a measure of how many of the true positive predictions were actually correct. It is defined as the number of true positives (TP) divided by the sum of true positives (TP) and false positives (FP).\n\n<p class=\"formulaDsp\">\n\\[ Precision = \\frac{TP}{TP + FP} \\]\n</p>\n\n#### **<span style='color:#85BB65'>Recall:</span>**\n\n\nRecall (or Sensitivity) is a measure of how many of the actual positive cases were identified correctly. It is defined as the number of true positives (TP) divided by the sum of true positives (TP) and false negatives (FN).\n\n<br>\n\n<p class=\"formulaDsp\">\n\\[ Recall = \\frac{TP}{TP + FN} \\]\n</p>\n\n#### **<span style='color:#85BB65'>F1-Score:</span>**\n\n\nThe F1 score is the harmonic mean of Precision and Recall and tries to find the balance between precision and recall. It is defined as 2 times the product of precision and recall divided by the sum of precision and recall.\n\n<br>\n\n<p class=\"formulaDsp\">\n\\[ F1 Score = \\frac{2 * Precision * Recall}{Precision + Recall} \\]\n</p>\n\n<br>\n    \n<div style=\"border-radius:10px;border:#85BB65 solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">     \n    <b><span style='color:#85BB65'>|</span> In all of these formulas: </b>\n    \nTrue Positives (TP) are the cases in which we predicted yes (diabetes present), and the actual was also yes.\nTrue Negatives (TN) are the cases in which we predicted no, and the actual was also no.\nFalse Positives (FP) are the cases in which we predicted yes, but the actual was no.\nFalse Negatives (FN) are the cases in which we predicted no, but the actual was yes.   \n</div>  ","metadata":{}},{"cell_type":"code","source":"# Generate the confusion matrix\ny_pred = best_model.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', xticklabels=salary_labels, yticklabels=salary_labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Print classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names=salary_labels))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:24.518483Z","iopub.execute_input":"2023-05-29T05:14:24.519364Z","iopub.status.idle":"2023-05-29T05:14:25.125079Z","shell.execute_reply.started":"2023-05-29T05:14:24.519316Z","shell.execute_reply":"2023-05-29T05:14:25.123857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#85BB65'>|</span> Result and Diccussion</b>\n\n<br>\n\nBased on the scores,the  **<mark style=\"background-color:#85BB65;color:white;border-radius:5px;opacity:1.0\">Gradient Boosting Classifiers</mark>**  performs the best among the tested models, **with an accuracy score of  0.32** . However, the overall performance of all models seems to be quite low, which might indicate that the models are not able to capture the relationship between the features and the target variable (adjusted_salary) very well.\n<br>\n\n#### **<span style='color:#85BB65'>There are several ways to potentially improve the model performance:</span>**\n\n1. **Feature Engineering:** Create new features or transform existing features to better capture the relationship between the features and the target variable. For example, you could try combining certain categorical features or creating interaction terms between features.\n\n2. **Feature Selection:** Investigate the importance of each feature in the model and consider removing less important features to reduce noise and improve the model's performance.\n\n3. **Model Tuning:** Perform hyperparameter tuning for the models, especially for complex models like **<mark style=\"background-color:#85BB65;color:white;border-radius:5px;opacity:1.0\">RandomForestRegressor</mark>** and **<mark style=\"background-color:#85BB65;color:white;border-radius:5px;opacity:1.0\">GradientBoostingRegressor</mark>**, to find the best set of hyperparameters that could improve their performance.\n\n4. **Try Different Models:** Experiment with other machine learning algorithms or try ensemble methods, such as stacking or bagging, to see if they can yield better results.\n\n5. **Collect More Data:** If possible, gather more data to provide the models with more information to learn from. This can help improve their performance.\n\n<br>\n\n> Remember that model performance can vary depending on the specific dataset and problem, and it's essential to experiment with different approaches to find the most suitable solution.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#E888BB; font-size: 1%;\">EXTRA | Who makes the most money</span>\n<div style=\"padding: 30px;color:white;margin:10;font-size:150%;text-align:left;display:fill;border-radius:10px;background-color:#F1C40F;overflow:hidden;background-image: url(https://images.pexels.com/photos/5466790/pexels-photo-5466790.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>EXTRA | Who makes the most money </span></b> </div>","metadata":{}},{"cell_type":"code","source":"# Visualize the adjusted_salary by different categories\ncat_columns = ['employment_type', 'job_category', 'experience_level', 'employee_residence', 'remote_ratio', 'company_location', 'company_size']\n\n# Determine the best categories for maximizing salary\ndef get_best_categories(df, cat_columns):\n    best_categories = {}\n    for col in cat_columns:\n        best_category = df.groupby(col)['adjusted_salary'].mean().idxmax()\n        best_categories[col] = best_category\n    return best_categories\n\nbest_categories = get_best_categories(df, cat_columns)\nprint(\"Best categories for maximizing adjusted salary:\")\nfor key, value in best_categories.items():\n    print(f\"{key.capitalize()}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:14:25.12672Z","iopub.execute_input":"2023-05-29T05:14:25.127087Z","iopub.status.idle":"2023-05-29T05:14:25.142774Z","shell.execute_reply.started":"2023-05-29T05:14:25.127057Z","shell.execute_reply":"2023-05-29T05:14:25.141896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n\n<br>\n\n<div style=\"text-align: center;\">\n   <span style=\"font-size: 4.5em; font-weight: bold; font-family: Arial;\">THANK YOU!</span>\n</div>\n\n<div style=\"text-align: center;\">\n    <span style=\"font-size: 5em;\">‚úîÔ∏è</span>\n</div>\n\n<br>\n\n<div style=\"text-align: center;\">\n   <span style=\"font-size: 1.4em; font-weight: bold; font-family: Arial; max-width:1200px; display: inline-block;\">\n       If you discovered this notebook to be useful or enjoyable, I'd greatly appreciate any upvotes! Your support motivates me to regularly update and improve it. :-)\n   </span>\n</div>\n\n<br>\n\n<br>\n\n<div style=\"text-align: center;\">\n   <span style=\"font-size: 1.2em; font-weight: bold;font-family: Arial;\">@pannmie</span>\n</div>","metadata":{}}]}